{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 · Exploración inicial de `Tab_Clientes(2)`\n",
        "\n",
        "Fecha: 2025-08-10\n",
        "\n",
        "Objetivo: entender estructura, nulos y valores para definir variables del clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "import os, pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Carpeta raíz del proyecto (sube un nivel desde /notebooks)\n",
        "ROOT = Path.cwd().parent\n",
        "DEFAULT = ROOT / \"data\" / \"raw\" / \"Tab_Clientes(2).csv\"\n",
        "\n",
        "# Permite override con .env si algún día quieres mover la ruta\n",
        "DATA_PATH = Path(os.getenv(\"DATA_PATH\", str(DEFAULT)))\n",
        "\n",
        "import os\n",
        "os.environ.pop(\"DATA_PATH\", None)  # borra cualquier override\n",
        "\n",
        "print(\"Usando CSV en:\", DATA_PATH)\n",
        "assert DATA_PATH.exists(), f\"No encuentro el CSV en: {DATA_PATH}\\n\" \\\n",
        "                           f\"Revisa que esté en data/raw o define DATA_PATH en un .env\"\n",
        "\n",
        "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
        "pd.set_option(\"display.max_columns\", None)  # no truncar columnas\n",
        "pd.set_option(\"display.width\", None) \n",
        "df.shape, df.columns[:5].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02a16332",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resumen = pd.DataFrame({\n",
        "    'Tipo': df.dtypes.astype(str),\n",
        "    'Nulos': df.isna().sum(),\n",
        "    '%Nulos': (df.isna().sum()/len(df)*100).round(2)\n",
        "}).sort_values('%Nulos', ascending=False)\n",
        "resumen.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32eb9fe",
      "metadata": {},
      "source": [
        "## Identificadores y duplicados\n",
        "### Objetivo: validar si RutBeneficiario identifica único a cada fila o si hay duplicados (mismo beneficiario con múltiples registros)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ec8344",
      "metadata": {},
      "outputs": [],
      "source": [
        "id_col = \"RutBeneficiario\"\n",
        "n_total = len(df)\n",
        "n_unicos = df[id_col].nunique(dropna=True)\n",
        "dupes = (\n",
        "    df[id_col]\n",
        "    .value_counts(dropna=True)\n",
        "    .loc[lambda s: s>1]\n",
        ")\n",
        "\n",
        "print(\"Filas totales:\", n_total)\n",
        "print(\"IDs únicos:\", n_unicos)\n",
        "print(\"Duplicados (IDs con >1 fila):\", len(dupes))\n",
        "dupes.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "455338f4",
      "metadata": {},
      "source": [
        "## Fechas (detección y rangos)\n",
        "### Objetivo: ver cuáles columnas parsean bien como fecha y sus rangos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddf42558",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Solo columnas de texto\n",
        "obj_cols = df.columns[df.dtypes == \"object\"].tolist()\n",
        "\n",
        "# 2) Candidatas por nombre (fechas reales)\n",
        "posibles_fechas = [\"Fec_Nac\",\"FechaRegistro\",\"FechaUltimaVisita\",\"FecUltimoPptoCreado\",\"PrimeraFechaAtencion\"]\n",
        "candidatas_fecha = [c for c in posibles_fechas if c in obj_cols]\n",
        "\n",
        "# 3) Parseo controlado (ojo con dayfirst)\n",
        "parsed = {c: pd.to_datetime(df[c], errors=\"coerce\", dayfirst=True) for c in candidatas_fecha}\n",
        "\n",
        "# 4) % de parseo y rangos\n",
        "pct = {c: parsed[c].notna().mean() for c in candidatas_fecha}\n",
        "rangos = {c: (parsed[c].min(), parsed[c].max()) for c in candidatas_fecha if parsed[c].notna().any()}\n",
        "pct, rangos\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ed21285",
      "metadata": {},
      "source": [
        "## Validar “días desde última visita”\n",
        "### Objetivo: comprobar si DiasDesdeUltimaVisita coincide con FechaUltimaVisita (cuando existe)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1761cab6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Validación de DiasDesdeUltimaVisita vs. cálculo propio ---\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Base de trabajo: si ya creaste df_exp (con fechas parseadas), úsalo; si no, usa df.\n",
        "base = df_exp if 'df_exp' in locals() else df\n",
        "\n",
        "# 2) Parseo de FechaUltimaVisita como ISO -> dayfirst=False (evita warnings, interpreta bien YYYY-MM-DD)\n",
        "fuv = pd.to_datetime(base.get(\"FechaUltimaVisita\"), errors=\"coerce\", dayfirst=False)\n",
        "\n",
        "# 3) \"Fecha de corte observada\": la máxima fecha en la columna (solo para comparar).\n",
        "corte_obs = fuv.max()\n",
        "\n",
        "# 4) Cálculo nuestro de días: diferencia entre corte observado y cada FechaUltimaVisita.\n",
        "calc_dias = (corte_obs - fuv).dt.days\n",
        "\n",
        "# 5) Columna real del sistema a numérico (maneja nulos/strings).\n",
        "real = pd.to_numeric(base.get(\"DiasDesdeUltimaVisita\"), errors=\"coerce\")\n",
        "\n",
        "# 6) Filas comparables: donde ambas series tienen dato.\n",
        "mask = fuv.notna() & real.notna()\n",
        "\n",
        "# 7) Diferencia con signo: real (sistema) - calculado (nuestro)\n",
        "#    Si es >0, el sistema suele contar con un \"corte\" más adelante.\n",
        "diff = (real[mask] - calc_dias[mask])\n",
        "\n",
        "# 8) Métricas principales del desfase\n",
        "print(\"Filas comparables:\", int(mask.sum()))\n",
        "print(\"Mediana diferencia (días):\", float(diff.median()))\n",
        "print(\"P90 diferencia:\", float(diff.quantile(0.90)))\n",
        "print(\"Proporción |dif| <= 7 días:\", float((diff.abs() <= 7).mean()))\n",
        "\n",
        "# 9) Dirección del desfase (distribución de signos)\n",
        "signo = diff.map(lambda x: 1 if x>0 else (-1 if x<0 else 0))\n",
        "print(\"Signo de la diferencia → proporciones:\", signo.value_counts(normalize=True).to_dict())\n",
        "\n",
        "# 10) “Offset documental”: lo dejamos anotado para Notion (no lo usamos en el modelo)\n",
        "offset_documental = float(diff.median())\n",
        "print(\"Offset documental sugerido:\", int(round(offset_documental)), \"días\")\n",
        "\n",
        "# 11) Decisión operativa explícita\n",
        "usar_columna_sistema = True\n",
        "print(\"Usaremos DiasDesdeUltimaVisita del sistema:\", usar_columna_sistema)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "175bd15f",
      "metadata": {},
      "source": [
        "## Presupuestos (calidad y outliers)\n",
        "### Objetivo: ver nulos/ceros y magnitudes para tomar decisiones de limpieza (y luego derivar KPIs en el 02)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce9f5f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 0) Base de trabajo: si ya tienes df_exp (con fechas parseadas/flags), úsalo. Si no, df.\n",
        "base = df_exp if 'df_exp' in locals() else df\n",
        "\n",
        "# ── 1) Definimos las columnas de presupuestos (cuentas y montos)\n",
        "cols_p = [\"CantPptos\",\"TotPptos\",\"CantPptosAbo\",\"TotPptosAbo\",\"CantPptosAvan\",\"TotPptosAvan\"]\n",
        "cols_p = [c for c in cols_p if c in base.columns]  # por si falta alguna\n",
        "\n",
        "# ── 2) Tasa de nulos y de ceros (calidad y “ausencia” de actividad)\n",
        "nulos = base[cols_p].isna().mean().round(3)\n",
        "ceros = (base[cols_p] == 0).mean().round(3)\n",
        "\n",
        "# ── 3) Búsqueda de valores negativos (deberían ser 0 en clínicas; si aparecen, son errores)\n",
        "negativos = (base[cols_p] < 0).sum()\n",
        "\n",
        "# ── 4) Estadísticos y percentiles altos (cola larga = posible outlier)\n",
        "stat = base[cols_p].describe(percentiles=[.5,.9,.95,.99]).T\n",
        "\n",
        "# ── 5) ¿Quiénes “tienen presupuestos”? (al menos una de las columnas no nula)\n",
        "tiene_ppto = base[cols_p].notna().any(axis=1)\n",
        "prop_tiene_ppto = tiene_ppto.mean().round(3)\n",
        "\n",
        "# ── 6) Resumen compacto para leer en una tabla\n",
        "resumen = pd.concat([\n",
        "    nulos.rename(\"pct_nulos\"),\n",
        "    ceros.rename(\"pct_ceros\"),\n",
        "    negativos.rename(\"n_negativos\")\n",
        "], axis=1).join(stat)\n",
        "\n",
        "print(\"Filas totales:\", len(base))\n",
        "print(\"Proporción con algún dato de presupuestos:\", prop_tiene_ppto)\n",
        "resumen\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cab2fb4c",
      "metadata": {},
      "source": [
        "## Ventanas de atención (cobertura y correlación)\n",
        "### Objetivo: ver en cuáles ventanas hay más actividad y qué tan redundantes son."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5406ed5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 0) Base: usamos df_exp si existe; si no, df.\n",
        "base = df_exp if 'df_exp' in locals() else df\n",
        "\n",
        "# ── 1) Detectamos TODAS las columnas que empiezan por \"Atencion\"\n",
        "#     (sin depender de mayúsculas; así no nos saltamos ninguna)\n",
        "att_cols = [c for c in base.columns if c.lower().startswith(\"atencion\")]\n",
        "print(\"Columnas de atención detectadas:\", att_cols, \"\\n\")\n",
        "\n",
        "# ── 2) Cobertura: ¿qué % de filas tiene valor > 0 en cada ventana?\n",
        "#     (Si alguien tuvo al menos 1 atención en la ventana, cuenta como 1)\n",
        "cover = (\n",
        "    base[att_cols]\n",
        "    .fillna(0)\n",
        "    .gt(0)                 # True si >0\n",
        "    .mean()                # promedio → % de filas con True\n",
        "    .sort_values(ascending=False)\n",
        "    .round(4)\n",
        ")\n",
        "print(\"Cobertura (>0) por ventana (ordenadas):\\n\", cover, \"\\n\")\n",
        "\n",
        "# ── 3) Marcamos columnas que NO aportan (cobertura 0 → siempre vacías)\n",
        "drop_zero = cover[cover == 0].index.tolist()\n",
        "print(\"Candidatas a descartar por cobertura 0:\", drop_zero, \"\\n\")\n",
        "\n",
        "# ── 4) Redundancia: correlación entre ventanas (¿cuáles se mueven juntas?)\n",
        "#     Si dos columnas están muy correlacionadas (>= 0.9), básicamente cuentan lo mismo.\n",
        "X = base[att_cols].fillna(0)\n",
        "corr = X.corr()\n",
        "\n",
        "pairs = (\n",
        "    corr.where(~np.eye(corr.shape[0], dtype=bool))  # anulamos diagonal\n",
        "        .stack()\n",
        "        .rename(\"corr\")\n",
        "        .sort_values(ascending=False)\n",
        ")\n",
        "\n",
        "high = pairs[pairs.abs() >= 0.90]   # umbral de \"muy similares\"\n",
        "print(\"Pares muy correlacionados (|r| >= 0.90):\\n\", high.head(10), \"\\n\")\n",
        "\n",
        "# ── 5) Selección automática (greedy): \n",
        "#     vamos agregando ventanas de mayor cobertura, \n",
        "#     pero saltamos las que están muy correlacionadas (> 0.9) con alguna ya elegida.\n",
        "seleccion = []\n",
        "thr = 0.90\n",
        "for c in cover.index:\n",
        "    if c in drop_zero:\n",
        "        continue\n",
        "    if all(abs(corr.loc[c, s]) < thr for s in seleccion):\n",
        "        seleccion.append(c)\n",
        "\n",
        "print(\"Selección greedy (sin colinealidad alta):\", seleccion, \"\\n\")\n",
        "\n",
        "# ── 6) Propuesta humana (simple y entendible):\n",
        "#     cubrir todo el eje temporal con pocas ventanas y sin redundancia clara.\n",
        "propuesta_humana = [c for c in [\"Atencion15d\",\"Atencion1m\",\"Atencion3m\",\"Atencion6m\",\"Atencion1a\",\"Atencion2a\"] if c in att_cols]\n",
        "print(\"Propuesta humana:\", propuesta_humana)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81954c0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base de trabajo\n",
        "base = df_exp if 'df_exp' in locals() else df\n",
        "\n",
        "# Selección acordada\n",
        "att_selected = [c for c in [\"Atencion15d\",\"Atencion1m\",\"Atencion3m\",\"Atencion6m\",\"Atencion1a\",\"Atencion2a\"] if c in base.columns]\n",
        "\n",
        "# Creamos variables de presencia (0/1)\n",
        "df_att = base.copy()\n",
        "for c in att_selected:\n",
        "    df_att[c + \"_pres\"] = (df_att[c].fillna(0) > 0).astype(int)\n",
        "\n",
        "# Resumen de cobertura de las nuevas columnas\n",
        "pres_cols = [c + \"_pres\" for c in att_selected]\n",
        "coverage_pres = df_att[pres_cols].mean().sort_values(ascending=False).round(4)\n",
        "print(\"Features de presencia creadas:\", pres_cols)\n",
        "print(\"\\nCobertura (proporción=1) por ventana seleccionada:\\n\", coverage_pres)\n",
        "\n",
        "# (Opcional) guardamos un intermedio para revisar luego\n",
        "from pathlib import Path\n",
        "Path(\"../data/interim\").mkdir(parents=True, exist_ok=True)\n",
        "df_att[pres_cols].to_csv(\"../data/interim/atencion_presencia_v1.csv\", index=False)\n",
        "print(\"\\nExportado: ../data/interim/atencion_presencia_v1.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4d3708e",
      "metadata": {},
      "source": [
        "## Geografía (cardinalidad)\n",
        "### Objetivo: ver si conviene usar Comuna tal cual (mucha cardinalidad) o agrupar/usar Región."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a42202a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 0) Base de trabajo: usamos df_exp si existe (ya con fechas/flags), si no df\n",
        "base = df_exp if 'df_exp' in locals() else df\n",
        "\n",
        "# ── 1) Elegimos N (cuántas comunas dejaremos \"tal cual\")\n",
        "TOP_N = 20  # puedes cambiarlo luego si te parece mucho/poco\n",
        "\n",
        "# ── 2) Conteo de comunas para ver las más frecuentes\n",
        "comunas_count = (\n",
        "    base[\"Comuna\"]\n",
        "    .fillna(\"Sin Comuna\")    # homogeneizamos nulos\n",
        "    .astype(str)\n",
        "    .value_counts()\n",
        ")\n",
        "\n",
        "# ── 3) Construimos una versión agrupada: Top-N, \"Sin Comuna\" explícito, resto a Otras/Infreq\n",
        "top_comunas = comunas_count.head(TOP_N).index\n",
        "def agrupar_comuna(x):\n",
        "    x = \"Sin Comuna\" if pd.isna(x) or str(x).strip()==\"\" else str(x)\n",
        "    if x == \"Sin Comuna\":\n",
        "        return \"Sin Comuna\"\n",
        "    return x if x in top_comunas else \"Otras/Infreq\"\n",
        "\n",
        "df_geo = base.copy()\n",
        "df_geo[\"Comuna_grp\"] = df_geo[\"Comuna\"].map(agrupar_comuna)\n",
        "\n",
        "# ── 4) Foto rápida para entender la distribución (cuenta y proporción)\n",
        "dist = (\n",
        "    df_geo[\"Comuna_grp\"]\n",
        "    .value_counts()\n",
        "    .to_frame(\"n\")\n",
        "    .assign(pct=lambda t: (t[\"n\"]/len(df_geo)).round(4))\n",
        "    .sort_values(\"n\", ascending=False)\n",
        ")\n",
        "print(\"Top categorías en Comuna_grp:\")\n",
        "print(dist.head(15), \"\\n\")\n",
        "\n",
        "# ── 5) One-hot (dummies) de Comuna agrupada + Región\n",
        "cols_cat = []\n",
        "if \"Comuna_grp\" in df_geo.columns:\n",
        "    cols_cat.append(\"Comuna_grp\")\n",
        "if \"Region\" in df_geo.columns:\n",
        "    cols_cat.append(\"Region\")\n",
        "\n",
        "dummies = pd.get_dummies(\n",
        "    df_geo[cols_cat],\n",
        "    drop_first=False,      # no colapsamos ninguna; para clustering no hace falta “evitar colinealidad”\n",
        "    dtype=\"uint8\"\n",
        ")\n",
        "\n",
        "print(f\"Se generaron {dummies.shape[1]} columnas dummie de {cols_cat}.\\nEjemplo de columnas:\", dummies.columns[:10].tolist(), \"\\n\")\n",
        "\n",
        "# ── 6) Guardar intermedios para inspección\n",
        "Path(\"../data/interim\").mkdir(parents=True, exist_ok=True)\n",
        "dist.to_csv(\"../data/interim/geografia_distribucion.csv\")\n",
        "dummies.to_csv(\"../data/interim/geografia_dummies_v1.csv\", index=False)\n",
        "print(\"Exportados: ../data/interim/geografia_distribucion.csv y ../data/interim/geografia_dummies_v1.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd3c24c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "df_exp = df.copy()\n",
        "\n",
        "# 1) Convertimos fechas generales (las que no son ambiguas) con dayfirst=False\n",
        "fecha_cols = [\"Fec_Nac\",\"FechaRegistro\",\"FechaUltimaVisita\"]\n",
        "fecha_cols = [c for c in fecha_cols if c in df_exp.columns]\n",
        "for c in fecha_cols:\n",
        "    df_exp[c] = pd.to_datetime(df_exp[c], errors=\"coerce\", dayfirst=False)\n",
        "\n",
        "# 2) Columnas de planificación: usar dayfirst=True por formato local (DD/MM/AAAA)\n",
        "hoy = pd.Timestamp(datetime.now().date())\n",
        "cols_planif = [c for c in [\"PrimeraFechaAtencion\",\"FecUltimoPptoCreado\"] if c in df_exp.columns]\n",
        "\n",
        "for c in cols_planif:\n",
        "    s = pd.to_datetime(df_exp[c], errors=\"coerce\", dayfirst=True)\n",
        "    df_exp[c] = s\n",
        "    df_exp[f\"{c}_es_planificada\"] = s > hoy\n",
        "    df_exp[f\"{c}_dias_hasta\"] = (s - hoy).dt.days.where(s > hoy)\n",
        "\n",
        "# 3) Indicador agregado\n",
        "plan_cols_flag = [f\"{c}_es_planificada\" for c in cols_planif]\n",
        "df_exp[\"TieneAgendamientoFuturo\"] = df_exp[plan_cols_flag].any(axis=1) if plan_cols_flag else False\n",
        "\n",
        "# 4) Resumen\n",
        "print(\"Columnas de planificación evaluadas:\", cols_planif)\n",
        "for c in cols_planif:\n",
        "    print(f\"  {c}_es_planificada ->\", df_exp[f\"{c}_es_planificada\"].mean().round(4), \"proporción\")\n",
        "    desc = df_exp[f\"{c}_dias_hasta\"].describe(percentiles=[.5,.9,.95]).dropna()\n",
        "    print(f\"  {c}_dias_hasta     ->\")\n",
        "    print(desc if not desc.empty else \"   (sin futuros)\")\n",
        "\n",
        "print(\"\\nTieneAgendamientoFuturo ->\", df_exp[\"TieneAgendamientoFuturo\"].mean().round(4), \"proporción total\")\n",
        "\n",
        "# 5) Guardamos copia exploratoria (no subir a Git)\n",
        "#Path(\"../data/interim\").mkdir(parents=True, exist_ok=True)\n",
        "#df_exp.to_csv(\"../data/interim/df_exploracion_paso2.csv\", index=False)\n",
        "#print(\"\\nExportado a ../data/interim/df_exploracion_paso2.csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7323d3e",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
