{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e20495",
   "metadata": {},
   "source": [
    "## Validaci√≥n con Prestaciones (V2): KPIs 2025 y Cohorte\n",
    "### Pagado es booleano (TRUE/FALSE), no monto.\n",
    "### Los montos abonados no se pueden calcular con este CSV; trabajamos con conteos por paciente y cohorte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e8c7d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths & imports\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Siempre funciona estando dentro o fuera de /notebooks\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PREST_PATH = ROOT / \"data\" / \"raw\" / \"ETL_vPrestaciones (2).csv\"\n",
    "\n",
    "assert PREST_PATH.exists(), f\"No encuentro: {PREST_PATH}\"\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga y columnas clave\n",
    "\n",
    "dfp = pd.read_csv(PREST_PATH, low_memory=False)\n",
    "\n",
    "# Fechas\n",
    "fecha      = pd.to_datetime(dfp.get('Fecha'), errors='coerce', dayfirst=True)\n",
    "fec_estado = pd.to_datetime(dfp.get('Fec_Estado'), errors='coerce', dayfirst=True)\n",
    "\n",
    "# A√±o/mes para presupuesto (Fecha) y pago (Fec_Estado; si falta, cae a Fecha)\n",
    "anio_ppto = fecha.dt.year\n",
    "mes_ppto  = fecha.dt.month\n",
    "anio_pago = fec_estado.dt.year.fillna(anio_ppto)\n",
    "mes_pago  = fec_estado.dt.month.fillna(mes_ppto)\n",
    "\n",
    "# Pagado booleano robusto\n",
    "pag_str  = dfp.get('Pagado', pd.Series(index=dfp.index, dtype=object)).astype(str).str.strip().str.upper()\n",
    "pag_bool = pag_str.map({'TRUE': True, 'FALSE': False, '1': True, '0': False, 'SI': True, 'NO': False}).fillna(False)\n",
    "\n",
    "# RUT\n",
    "rut_col = 'RUT' if 'RUT' in dfp.columns else ('RutBeneficiario' if 'RutBeneficiario' in dfp.columns else None)\n",
    "assert rut_col is not None, \"No encuentro columna de RUT.\"\n",
    "print(\"Filas Prestaciones:\", len(dfp), \"| Cols:\", len(dfp.columns), \"| RUT:\", rut_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1451b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA r√°pido de Pagado/Estado\n",
    "\n",
    "def top_vals(s, n=10):\n",
    "    return (s.astype(str).str.strip().str.upper()\n",
    "            .replace({'': '(VAC√çO)', 'NAN': '(NULO)'})\n",
    "            .value_counts().head(n))\n",
    "\n",
    "print(\"TOP Pagado:\\n\", top_vals(dfp['Pagado']))\n",
    "print(\"\\nTOP Estado:\\n\", top_vals(dfp.get('Estado', pd.Series(dtype=object))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f763fd53",
   "metadata": {},
   "source": [
    "# KPIs 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPIs por paciente y series\n",
    "\n",
    "# Detectar una columna de monto de presupuesto (para exigir >0). Si no hay, basta con la existencia.\n",
    "m_ppto = None\n",
    "for cand in ['Valor_Total','Precio_Total','Valor_Prest','Precio']:\n",
    "    if cand in dfp.columns:\n",
    "        m_ppto = cand; break\n",
    "\n",
    "if m_ppto is not None:\n",
    "    monto = pd.to_numeric(dfp[m_ppto], errors='coerce')\n",
    "    mask_ppto_2025 = anio_ppto.eq(2025) & (monto > 0)\n",
    "else:\n",
    "    mask_ppto_2025 = anio_ppto.eq(2025)\n",
    "\n",
    "mask_pago_2025 = anio_pago.eq(2025) & pag_bool\n",
    "\n",
    "# KPIs por paciente √∫nico\n",
    "pacientes_ppto_2025 = dfp.loc[mask_ppto_2025, rut_col].dropna().astype(str).nunique()\n",
    "pacientes_pago_2025 = dfp.loc[mask_pago_2025, rut_col].dropna().astype(str).nunique()\n",
    "\n",
    "# Series mensuales (pacientes √∫nicos por mes)\n",
    "serie_ppto = (dfp.loc[mask_ppto_2025, [rut_col]]\n",
    "                .assign(_mes=mes_ppto[mask_ppto_2025].astype('Int64'))\n",
    "                .dropna().drop_duplicates()\n",
    "                .groupby('_mes')[rut_col].nunique()\n",
    "                .reindex(range(1,13), fill_value=0))\n",
    "\n",
    "serie_pago = (dfp.loc[mask_pago_2025, [rut_col]]\n",
    "                .assign(_mes=mes_pago[mask_pago_2025].astype('Int64'))\n",
    "                .dropna().drop_duplicates()\n",
    "                .groupby('_mes')[rut_col].nunique()\n",
    "                .reindex(range(1,13), fill_value=0))\n",
    "\n",
    "# Top convenios entre quienes pagaron en 2025\n",
    "if 'Convenio' in dfp.columns:\n",
    "    top_conv_pago = (dfp.loc[mask_pago_2025, [rut_col,'Convenio']]\n",
    "                       .dropna()\n",
    "                       .drop_duplicates(rut_col)['Convenio']\n",
    "                       .astype(str).str.upper()\n",
    "                       .value_counts().head(10))\n",
    "else:\n",
    "    top_conv_pago = pd.Series(dtype='int64')\n",
    "\n",
    "kpis_2025 = {\n",
    "    'pacientes_ppto_creado_2025': int(pacientes_ppto_2025),\n",
    "    'pacientes_con_abono_2025'  : int(pacientes_pago_2025),\n",
    "    'nota' : 'Pagos 2025 incluyen arrastre de presupuestos antiguos (no linkeamos por ID).'\n",
    "}\n",
    "\n",
    "print(\"KPIs 2025 (conteos por paciente):\", kpis_2025)\n",
    "print(\"\\nPacientes con ppto por mes (2025):\\n\", serie_ppto)\n",
    "print(\"\\nPacientes con abono por mes (2025):\\n\", serie_pago)\n",
    "print(\"\\nTop convenios (pagaron en 2025):\\n\", top_conv_pago)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a6c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohorte 2025\n",
    "# Cohorte: pacientes que crearon Ppto en 2025 (mask_ppto_2025)\n",
    "cohorte_2025      = set(dfp.loc[mask_ppto_2025, rut_col].dropna().astype(str).unique())\n",
    "pagadores_2025    = set(dfp.loc[mask_pago_2025, rut_col].dropna().astype(str).unique())\n",
    "pag_en_cohorte    = len(cohorte_2025 & pagadores_2025)\n",
    "n_cohorte         = len(cohorte_2025)\n",
    "tasa_cohorte_2025 = (pag_en_cohorte / n_cohorte) if n_cohorte else np.nan\n",
    "\n",
    "print({\n",
    "    \"cohorte_pacientes_ppto_2025\": n_cohorte,\n",
    "    \"pagadores_2025_en_cohorte\"  : pag_en_cohorte,\n",
    "    \"tasa_pago_en_misma_cohorte\" : None if pd.isna(tasa_cohorte_2025) else round(tasa_cohorte_2025, 3)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8353267",
   "metadata": {},
   "source": [
    "# Export mini-resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bded72",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = ROOT / \"data\" / \"interim\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "(serie_ppto.rename(\"pacientes_ppto_mes_2025\")\n",
    "           .to_csv(OUT_DIR / \"prest_serie_ppto_2025.csv\", index=True))\n",
    "(serie_pago.rename(\"pacientes_pago_mes_2025\")\n",
    "           .to_csv(OUT_DIR / \"prest_serie_pago_2025.csv\", index=True))\n",
    "\n",
    "pd.Series(kpis_2025).to_csv(OUT_DIR / \"prest_kpis_2025_conteos.csv\")\n",
    "print(\"Exportados a:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Export NB-06: Cohortes y QA de reglas ===\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Definir ruta a carpeta reports\n",
    "reports_path = Path(ROOT, \"reports\")\n",
    "reports_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Construir DataFrame con resultados globales de cohortes\n",
    "df_prest_val = pd.DataFrame({\n",
    "    \"Corte\": [\"2025\"],\n",
    "    \"Pacientes_con_Ppto\": [4564],\n",
    "    \"Pacientes_con_Pago\": [4862],\n",
    "    \"Pacientes_con_Ambos\": [3951],\n",
    "    \"Tasa_Conversion\": [3951 / 4564]  # ~0.91\n",
    "})\n",
    "\n",
    "# Exportar a CSV\n",
    "export_path = reports_path / \"nb06_prestaciones_validacion.csv\"\n",
    "df_prest_val.to_csv(export_path, index=False)\n",
    "\n",
    "print(\"Archivo exportado en:\", export_path)\n",
    "df_prest_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c549608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Comparativa por Cluster (NB-06) ‚Äî Celda √öNICA (FIX flags Ppto/Pago) ===\n",
    "# Requisitos previos:\n",
    "#  - dfp (prestaciones) ya cargado\n",
    "#  - rut_col y fecha_col definidos en celdas anteriores (si no, descomenta las 2 l√≠neas marcadas)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# (Descomenta si NO est√°n definidas arriba)\n",
    "# rut_col = \"RutBeneficiario\"   # o \"RUT\"\n",
    "# fecha_col = \"Fec_Estado\"      # o \"Fecha\", etc.\n",
    "\n",
    "# 0) ROOT y clusters\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "CLUSTERS_PATH = ROOT / \"data\" / \"processed\" / \"activos_ids_v2_plus_clustered.csv\"\n",
    "assert CLUSTERS_PATH.exists(), f\"No encuentro {CLUSTERS_PATH}.\"\n",
    "dfc = pd.read_csv(CLUSTERS_PATH)\n",
    "\n",
    "# Usaremos baseline para ser consistentes con NB-04\n",
    "assert \"cluster_baseline\" in dfc.columns, \"La tabla clustered no tiene 'cluster_baseline'.\"\n",
    "rut_key_clusters = \"RutBeneficiario\" if \"RutBeneficiario\" in dfc.columns else (\"RUT\" if \"RUT\" in dfc.columns else None)\n",
    "assert rut_key_clusters is not None, \"No encuentro columna de RUT en la tabla clustered.\"\n",
    "dfc = dfc.rename(columns={\"cluster_baseline\": \"Cluster\"})\n",
    "\n",
    "# 1) Preparar a√±o en prestaciones + recorte 2025\n",
    "dfp[\"anio\"] = pd.to_datetime(dfp[fecha_col], errors=\"coerce\").dt.year\n",
    "print(\"A√±os detectados en dfp:\", dfp[\"anio\"].dropna().value_counts().sort_index().tail())\n",
    "dfp_2025 = dfp[dfp[\"anio\"] == 2025].copy()\n",
    "print(\"Filas 2025:\", len(dfp_2025))\n",
    "\n",
    "# 2) Detecci√≥n ROBUSTA de columnas de Presupuesto / Pago\n",
    "cols_lower = {c: c.lower() for c in dfp_2025.columns}\n",
    "\n",
    "# Candidatas por nombre para \"ppto\" (num√©ricas o flags)\n",
    "ppto_name_candidates = [\n",
    "    \"tiene_ppto\",\"tieneppto\",\"flag_ppto\",\"presupuesto\",\"es_presupuesto\",\n",
    "    \"montopresupuesto\",\"totalpresupuesto\",\"ppto\",\"presu\"\n",
    "]\n",
    "# Candidatas por nombre para \"pago/abono\" (num√©ricas o flags)\n",
    "pago_name_candidates = [\n",
    "    \"tiene_pago\",\"tienepago\",\"flag_pago\",\"pagado\",\"pago\",\"abono\",\"abonos\",\n",
    "    \"montopago\",\"totalpago\",\"totalpagos\",\"montoabono\",\"totalabonos\",\"abonado\"\n",
    "]\n",
    "\n",
    "def find_cols(candidates):\n",
    "    found = []\n",
    "    for c in dfp_2025.columns:\n",
    "        lc = c.lower()\n",
    "        if any(x in lc for x in candidates):\n",
    "            found.append(c)\n",
    "    return found\n",
    "\n",
    "ppto_cols = find_cols(ppto_name_candidates)\n",
    "pago_cols = find_cols(pago_name_candidates)\n",
    "\n",
    "print(\"Cols detectadas ppto:\", ppto_cols)\n",
    "print(\"Cols detectadas pago:\", pago_cols)\n",
    "\n",
    "# 3) Construcci√≥n de flags con m√∫ltiples estrategias\n",
    "\n",
    "# 3.1 Flags desde columnas num√©ricas/booleanas candidatas\n",
    "def any_positive(df, cols):\n",
    "    if not cols:\n",
    "        return pd.Series(False, index=df.index)\n",
    "    num = df[cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    if num.shape[1] == 1:\n",
    "        return (num.iloc[:,0] > 0) | (df[cols[0]].astype(str).str.lower().isin([\"si\",\"true\",\"s√≠\"]))\n",
    "    return (num.sum(axis=1) > 0)\n",
    "\n",
    "dfp_2025[\"_has_ppto\"] = any_positive(dfp_2025, ppto_cols)\n",
    "dfp_2025[\"_has_pago\"] = any_positive(dfp_2025, pago_cols)\n",
    "\n",
    "# 3.2 Si siguen todos False, intentamos derivar por texto en columnas tipo \"Estado\"\n",
    "if (not dfp_2025[\"_has_ppto\"].any()) or (not dfp_2025[\"_has_pago\"].any()):\n",
    "    estado_cols = [c for c in dfp_2025.columns if re.search(r\"estado|situacion|tipo\", c, flags=re.IGNORECASE)]\n",
    "    if estado_cols:\n",
    "        estado_blob = dfp_2025[estado_cols].astype(str).apply(lambda s: s.str.cat(sep=\"|\"), axis=1).str.lower()\n",
    "        # Heur√≠stica por texto (ajusta keywords si usas otros)\n",
    "        dfp_2025[\"_has_ppto\"] = dfp_2025[\"_has_ppto\"] | estado_blob.str.contains(r\"presup|ppto|presu\")\n",
    "        dfp_2025[\"_has_pago\"]  = dfp_2025[\"_has_pago\"]  | estado_blob.str.contains(r\"pagad|pago|abon\")\n",
    "        print(\"Heur√≠stica por texto aplicada sobre columnas:\", estado_cols)\n",
    "\n",
    "# 3.3 Copiar EXACTAMENTE la l√≥gica del mini-resumen (por si lo anterior no captura tu caso)\n",
    "#     - Fecha de presupuesto: 'Fecha' -> anio_ppto\n",
    "#     - Fecha de pago: 'Fec_Estado' (o cae a 'Fecha') -> anio_pago\n",
    "#     - Pagado: normalizaci√≥n de 'Pagado'\n",
    "fecha      = pd.to_datetime(dfp.get('Fecha'), errors='coerce', dayfirst=True)\n",
    "fec_estado = pd.to_datetime(dfp.get('Fec_Estado'), errors='coerce', dayfirst=True)\n",
    "anio_ppto  = fecha.dt.year\n",
    "anio_pago  = fec_estado.dt.year.fillna(anio_ppto)\n",
    "\n",
    "pag_str  = dfp.get('Pagado', pd.Series(index=dfp.index, dtype=object)).astype(str).str.strip().str.upper()\n",
    "pag_bool = pag_str.map({'TRUE': True, 'FALSE': False, '1': True, '0': False, 'SI': True, 'NO': False}).fillna(False)\n",
    "\n",
    "m_ppto = None\n",
    "for cand in ['Valor_Total','Precio_Total','Valor_Prest','Precio']:\n",
    "    if cand in dfp.columns:\n",
    "        m_ppto = cand; break\n",
    "\n",
    "if m_ppto is not None:\n",
    "    monto = pd.to_numeric(dfp[m_ppto], errors='coerce')\n",
    "    mask_ppto_2025 = anio_ppto.eq(2025) & (monto > 0)\n",
    "else:\n",
    "    mask_ppto_2025 = anio_ppto.eq(2025)\n",
    "\n",
    "mask_pago_2025 = anio_pago.eq(2025) & pag_bool\n",
    "\n",
    "# Refuerzo de flags por fila (OR con lo anterior)\n",
    "dfp_2025[\"_has_ppto\"] = dfp_2025[\"_has_ppto\"] | mask_ppto_2025.loc[dfp_2025.index].fillna(False)\n",
    "dfp_2025[\"_has_pago\"]  = dfp_2025[\"_has_pago\"]  | mask_pago_2025.loc[dfp_2025.index].fillna(False)\n",
    "\n",
    "print(\"Resumen flags ‚Üí _has_ppto:\", int(dfp_2025[\"_has_ppto\"].sum()),\n",
    "      \"| _has_pago:\", int(dfp_2025[\"_has_pago\"].sum()))\n",
    "\n",
    "# 4) Agregaci√≥n por paciente (2025)\n",
    "agg_2025 = (dfp_2025\n",
    "            .groupby(rut_col)\n",
    "            .agg(has_ppto=(\"_has_ppto\",\"max\"),\n",
    "                 has_pago=(\"_has_pago\",\"max\"))\n",
    "            .reset_index())\n",
    "agg_2025[\"has_ambos\"] = agg_2025[\"has_ppto\"] & agg_2025[\"has_pago\"]\n",
    "\n",
    "# 5) Join con clusters\n",
    "aggc = agg_2025.merge(\n",
    "    dfc[[rut_key_clusters, \"Cluster\"]].rename(columns={rut_key_clusters: rut_col}),\n",
    "    on=rut_col, how=\"left\"\n",
    ")\n",
    "\n",
    "# 6) Conversi√≥n por cluster\n",
    "conv = aggc.groupby(\"Cluster\").agg(\n",
    "    n_pacientes=(\"has_ppto\",\"size\"),\n",
    "    ppto=(\"has_ppto\",\"sum\"),\n",
    "    pago=(\"has_pago\",\"sum\"),\n",
    "    ambos=(\"has_ambos\",\"sum\")\n",
    ")\n",
    "conv[\"tasa_conversion\"] = (conv[\"ambos\"] / conv[\"ppto\"]).replace([np.inf, -np.inf], np.nan).round(3)\n",
    "\n",
    "# 7) Export final\n",
    "reports_dir = ROOT / \"reports\" / \"entregables\"\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "conv_out = reports_dir / \"nb06_cluster_conversion_2025.csv\"\n",
    "conv.to_csv(conv_out)\n",
    "print(\"‚úî Export:\", conv_out.resolve())\n",
    "\n",
    "# 8) (Opcional) Mix de prestaciones si existe columna conocida de tipo\n",
    "tipo_col = None\n",
    "for c in [\"TipoPrestacion\",\"Prestacion\",\"Tipo_Prestacion\"]:\n",
    "    if c in dfp_2025.columns:\n",
    "        tipo_col = c\n",
    "        break\n",
    "\n",
    "if tipo_col:\n",
    "    mix = (dfp_2025.merge(dfc[[rut_key_clusters, \"Cluster\"]].rename(columns={rut_key_clusters: rut_col}),\n",
    "                          on=rut_col, how=\"left\")\n",
    "           .pivot_table(index=\"Cluster\", columns=tipo_col, values=rut_col, aggfunc=\"nunique\")\n",
    "           .fillna(0))\n",
    "    mix_pct = (mix.div(mix.sum(axis=1), axis=0).round(3))\n",
    "    mix_out = reports_dir / \"nb06_cluster_prestaciones_2025.csv\"\n",
    "    mix_pct.to_csv(mix_out)\n",
    "    print(\"‚úî Export:\", mix_out.resolve())\n",
    "else:\n",
    "    print(\"Aviso: no hay columna de tipo de prestaci√≥n (TipoPrestacion/Prestacion) ‚Üí se omite mix.\")\n",
    "\n",
    "print(\"\\n[OK] Comparativa por cluster terminada.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bd19c5",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Hist√≥rico V1 (no ejecutar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OBSOLETO: bloque V1, no ejecutar ---\n",
    "if False:\n",
    "    pass\n",
    "\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "    fp = ROOT / \"data\" / \"raw\" / \"ETL_vPrestaciones (2).csv\"\n",
    "\n",
    "    # 1) Cargar e inspeccionar\n",
    "    dfp = pd.read_csv(fp, low_memory=False)\n",
    "    print(\"Cols prestaciones:\", list(dfp.columns)[:30])\n",
    "\n",
    "    # 2) Mapea columnas (ajusta si difiere)\n",
    "    MAP = {\n",
    "        \"rut\":      [\"RutBeneficiario\",\"Rut\",\"RUT\",\"IdPaciente\",\"PacienteID\"],\n",
    "        \"fecha\":    [\"Fecha\",\"FechaAtencion\",\"FechaPpto\",\"FechaPresupuesto\",\"FechaRegistro\",\"Fec_Atencion\",\"Fec_Ppto\"],\n",
    "        \"tipo\":     [\"Tipo\",\"TipoPrestacion\",\"Movimiento\",\"Estado\",\"Evento\"],\n",
    "        # Monto total del Ppto y Monto abonado (ajusta si existen)\n",
    "        \"monto_ppto\":   [\"MontoPresupuestado\",\"TotalPresupuesto\",\"MontoPpto\",\"Total\",\"Valor\"],\n",
    "        \"monto_abono\":  [\"MontoAbonado\",\"Abonado\",\"Pagado\",\"MontoPago\",\"MontoAvance\"],\n",
    "    }\n",
    "\n",
    "    def pick(d, candidates):\n",
    "        for c in candidates:\n",
    "            if c in d.columns: return c\n",
    "        return None\n",
    "\n",
    "    col_rut   = pick(dfp, MAP[\"rut\"])\n",
    "    col_fecha = pick(dfp, MAP[\"fecha\"])\n",
    "    col_tipo  = pick(dfp, MAP[\"tipo\"])\n",
    "    col_mp    = pick(dfp, MAP[\"monto_ppto\"])\n",
    "    col_ma    = pick(dfp, MAP[\"monto_abono\"])\n",
    "\n",
    "    print(\"Usando columnas ->\", dict(rut=col_rut, fecha=col_fecha, tipo=col_tipo, monto_ppto=col_mp, monto_abono=col_ma))\n",
    "\n",
    "    # 3) Parse fecha y cortar 2025\n",
    "    f = pd.to_datetime(dfp[col_fecha], errors=\"coerce\", dayfirst=True)\n",
    "    dfp[\"_anio\"] = f.dt.year\n",
    "    dfp[\"_mes\"]  = f.dt.month\n",
    "    dfp_2025 = dfp[dfp[\"_anio\"].eq(2025)].copy()\n",
    "\n",
    "    # 4) Derivar KPIs aproximando las tarjetas de PBI\n",
    "    #   - Define reglas para \"ppto creado\", \"abono\" y \"avance\"\n",
    "    def flag_contains(s, patterns):\n",
    "        s = s.astype(str).str.upper()\n",
    "        pat = \"|\".join([p.upper() for p in patterns])\n",
    "        return s.str.contains(pat, regex=True)\n",
    "\n",
    "    if col_tipo is not None:\n",
    "        is_ppto  = flag_contains(dfp_2025[col_tipo], [\"PRESUPUESTO\",\"PPTO\",\"CREADO\"])\n",
    "        is_abono = flag_contains(dfp_2025[col_tipo], [\"ABONO\",\"PAGO\",\"COBRO\"])\n",
    "        is_avance= flag_contains(dfp_2025[col_tipo], [\"AVANCE\"])\n",
    "    else:\n",
    "        # Si no existe 'tipo', nos vamos por montos disponibles\n",
    "        is_ppto  = dfp_2025[col_mp].notna() if col_mp else pd.Series(False, index=dfp_2025.index)\n",
    "        is_abono = dfp_2025[col_ma].notna() if col_ma else pd.Series(False, index=dfp_2025.index)\n",
    "        is_avance= pd.Series(False, index=dfp_2025.index)\n",
    "\n",
    "    # 5) KPIs (2025)\n",
    "    kpis = {}\n",
    "\n",
    "    # Pacientes con ppto creado en 2025\n",
    "    if col_rut:\n",
    "        kpis[\"pacientes_ppto_creado\"] = int(dfp_2025.loc[is_ppto, col_rut].nunique())\n",
    "        kpis[\"pacientes_con_abono\"]   = int(dfp_2025.loc[is_abono, col_rut].nunique())\n",
    "        kpis[\"pacientes_con_avance\"]  = int(dfp_2025.loc[is_avance, col_rut].nunique())\n",
    "\n",
    "    # Montos\n",
    "    if col_mp:\n",
    "        kpis[\"monto_total_ppto_2025\"] = float(dfp_2025.loc[is_ppto, col_mp].sum())\n",
    "    if col_ma:\n",
    "        kpis[\"monto_total_abonos_2025\"] = float(dfp_2025.loc[is_abono, col_ma].sum())\n",
    "\n",
    "    # % Avance abonado (m√©tricas de PBI suelen ser sum(abonos)/sum(pptos))\n",
    "    if col_mp and col_ma and kpis.get(\"monto_total_ppto_2025\", 0) > 0:\n",
    "        kpis[\"pct_avance_abonado\"] = kpis[\"monto_total_abonos_2025\"] / kpis[\"monto_total_ppto_2025\"]\n",
    "\n",
    "    print(\"KPIs 2025 estimados:\", kpis)\n",
    "\n",
    "    # 6) Serie por mes (pacientes con ppto por mes)\n",
    "    if col_rut:\n",
    "        serie_mes = (dfp_2025.loc[is_ppto, [col_rut, \"_mes\"]]\n",
    "                    .dropna()\n",
    "                    .drop_duplicates()\n",
    "                    .groupby(\"_mes\")[col_rut].nunique()\n",
    "                    .reindex(range(1,13), fill_value=0))\n",
    "        print(\"Pacientes con ppto creado por mes (2025):\")\n",
    "        print(serie_mes)\n",
    "\n",
    "    # 7) Top convenios por paciente en 2025\n",
    "    #    Join con clientes para tomar Empresa/Convenio limpio\n",
    "    dfc = pd.read_csv(ROOT / \"data\" / \"raw\" / \"Tab_Clientes(2).csv\", low_memory=False)\n",
    "    # Tomar solo columnas necesarias\n",
    "    join_cols = [\"RutBeneficiario\",\"Empresa\"]\n",
    "    join_cols = [c for c in join_cols if c in dfc.columns]\n",
    "    dfc_j = dfc[join_cols].copy()\n",
    "\n",
    "    if col_rut and join_cols:\n",
    "        dfp_2025_u = dfp_2025.loc[is_ppto, [col_rut]].dropna().drop_duplicates()\n",
    "        top_conv = (dfp_2025_u.merge(dfc_j, left_on=col_rut, right_on=\"RutBeneficiario\", how=\"left\")\n",
    "                    .Empresa.astype(str).str.upper().value_counts().head(10))\n",
    "        print(\"Top convenios (pacientes con ppto 2025):\")\n",
    "        print(top_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc18b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OBSOLETO: bloque V1, no ejecutar ---\n",
    "if False:\n",
    "    pass\n",
    "\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "    dfp = pd.read_csv(ROOT / \"data\" / \"raw\" / \"ETL_vPrestaciones (2).csv\", low_memory=False)\n",
    "\n",
    "    # Parseo m√≠nimo\n",
    "    dfp['Fecha'] = pd.to_datetime(dfp['Fecha'], errors='coerce', dayfirst=True)\n",
    "    dfp['_anio'] = dfp['Fecha'].dt.year\n",
    "    dfp['_mes']  = dfp['Fecha'].dt.month\n",
    "\n",
    "    # Montos: ppto vs abonos\n",
    "    m_ppto = 'Valor_Total' if 'Valor_Total' in dfp.columns else ('Precio_Total' if 'Precio_Total' in dfp.columns else None)\n",
    "    m_abon = 'Pagado' if 'Pagado' in dfp.columns else None\n",
    "    assert m_abon is not None, \"No encuentro columna de abonos (Pagado).\"\n",
    "\n",
    "    # 2025\n",
    "    d25 = dfp[dfp['_anio'].eq(2025)].copy()\n",
    "\n",
    "    # Limpieza b√°sica de montos\n",
    "    for c in [m_ppto, m_abon]:\n",
    "        if c: d25[c] = pd.to_numeric(d25[c], errors='coerce').fillna(0)\n",
    "\n",
    "    # KPI por PACIENTE en 2025 (aprox tarjetas PBI)\n",
    "    agg_pac = (d25\n",
    "        .groupby('RUT')[[m_ppto, m_abon]]\n",
    "        .sum(min_count=1)\n",
    "        .fillna(0)\n",
    "        .rename(columns={m_ppto:'ppto_2025', m_abon:'abon_2025'}))\n",
    "\n",
    "    kpis = {\n",
    "        'pacientes_ppto_creado'   : int((agg_pac['ppto_2025'] > 0).sum()),\n",
    "        'pacientes_con_abono'     : int((agg_pac['abon_2025'] > 0).sum()),\n",
    "        'pacientes_ppto_en_avance': int(((agg_pac['abon_2025'] > 0) & (agg_pac['abon_2025'] < agg_pac['ppto_2025'])).sum()),\n",
    "        'monto_total_ppto_2025'   : float(agg_pac['ppto_2025'].sum()),\n",
    "        'monto_total_abonos_2025' : float(agg_pac['abon_2025'].sum()),\n",
    "    }\n",
    "    kpis['pct_avance_abonado'] = (kpis['monto_total_abonos_2025'] / kpis['monto_total_ppto_2025']) if kpis['monto_total_ppto_2025']>0 else np.nan\n",
    "    print(\"KPIs 2025 (aprox paciente):\", kpis)\n",
    "\n",
    "    # Serie mensual (pacientes con presupuesto por mes)\n",
    "    serie_mes = (d25.groupby(['_mes','RUT'])[m_ppto].sum().reset_index()\n",
    "                .query(f\"{m_ppto} > 0\")\n",
    "                .groupby('_mes')['RUT'].nunique()\n",
    "                .reindex(range(1,13), fill_value=0))\n",
    "    print(\"\\nPacientes con ppto por mes (2025):\")\n",
    "    print(serie_mes)\n",
    "\n",
    "    # Top convenios por paciente (usando Prestaciones directamente)\n",
    "    top_conv = (d25.groupby('RUT')['Convenio'].agg(lambda s: str(s.dropna().iloc[0]) if len(s.dropna()) else '(EN BLANCO)')\n",
    "                .value_counts().head(10))\n",
    "    print(\"\\nTop convenios por paciente (2025, Prestaciones):\")\n",
    "    print(top_conv)\n",
    "\n",
    "    # (Opcional) Comparar con 'Empresa' de Clientes:\n",
    "    dfc = pd.read_csv(ROOT / \"data\" / \"raw\" / \"Tab_Clientes(2).csv\", low_memory=False)\n",
    "    top_conv_emp = (d25[['RUT']].drop_duplicates()\n",
    "                    .merge(dfc[['RutBeneficiario','Empresa']], left_on='RUT', right_on='RutBeneficiario', how='left')\n",
    "                    .Empresa.astype(str).str.upper().value_counts().head(10))\n",
    "    print(\"\\nTop convenios por paciente (2025, via Empresa de Clientes):\")\n",
    "    print(top_conv_emp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ca613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OBSOLETO: bloque V1, no ejecutar ---\n",
    "if False:\n",
    "    pass\n",
    "\n",
    "    # Normalizaci√≥n de montos CLP con miles '.' y decimales ','\n",
    "    import pandas as pd\n",
    "    def parse_clp(s):\n",
    "        if s is None: \n",
    "            return pd.Series(dtype='float64')\n",
    "        return pd.to_numeric(\n",
    "            s.astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False),\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "    d25_norm = d25.copy()\n",
    "    if m_abon:  d25_norm[m_abon] = parse_clp(d25_norm[m_abon])\n",
    "    if m_ppto:  d25_norm[m_ppto] = parse_clp(d25_norm[m_ppto])\n",
    "\n",
    "    agg_pac_n = (d25_norm\n",
    "                .groupby('RUT')[[m_ppto, m_abon]]\n",
    "                .sum(min_count=1).fillna(0)\n",
    "                .rename(columns={m_ppto:'ppto_2025', m_abon:'abon_2025'}))\n",
    "\n",
    "    kpis_n = {\n",
    "        'pacientes_ppto_creado'   : int((agg_pac_n['ppto_2025'] > 0).sum()),\n",
    "        'pacientes_con_abono'     : int((agg_pac_n['abon_2025'] > 0).sum()),\n",
    "        'pacientes_ppto_en_avance': int(((agg_pac_n['abon_2025'] > 0) & (agg_pac_n['abon_2025'] < agg_pac_n['ppto_2025'])).sum()),\n",
    "        'monto_total_ppto_2025'   : float(agg_pac_n['ppto_2025'].sum()),\n",
    "        'monto_total_abonos_2025' : float(agg_pac_n['abon_2025'].sum()),\n",
    "    }\n",
    "    kpis_n['pct_avance_abonado'] = (kpis_n['monto_total_abonos_2025']/kpis_n['monto_total_ppto_2025']\n",
    "                                    if kpis_n['monto_total_ppto_2025']>0 else None)\n",
    "kpis_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OBSOLETO: bloque V1, no ejecutar ---\n",
    "if False:\n",
    "    pass\n",
    "\n",
    "    # DIAGN√ìSTICO: ¬øLos abonos 2025 est√°n fechados en Fec_Estado?\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "\n",
    "    ROOT = Path.cwd().parent if Path.cwd().name==\"notebooks\" else Path.cwd()\n",
    "    dfp = pd.read_csv(ROOT/\"data\"/\"raw\"/\"ETL_vPrestaciones (2).csv\", low_memory=False)\n",
    "\n",
    "    def parse_clp_series(s):\n",
    "        return pd.to_numeric(\n",
    "            s.astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False),\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "    fecha      = pd.to_datetime(dfp.get('Fecha'), errors='coerce', dayfirst=True)\n",
    "    fec_estado = pd.to_datetime(dfp.get('Fec_Estado'), errors='coerce', dayfirst=True)\n",
    "    pag        = parse_clp_series(dfp['Pagado']) if 'Pagado' in dfp.columns else pd.Series(dtype='float64')\n",
    "    estado     = dfp.get('Estado', pd.Series(index=dfp.index, dtype=str)).astype(str).str.upper()\n",
    "\n",
    "    print(\"Non-null Pagado:\", int(pag.notna().sum()), \" | Suma total (todas fechas):\", float(pag.fillna(0).sum()))\n",
    "\n",
    "    by_year_fecha = pag.groupby(fecha.dt.year).sum(min_count=1).dropna().sort_index()\n",
    "    by_year_fest  = pag.groupby(fec_estado.dt.year).sum(min_count=1).dropna().sort_index()\n",
    "    print(\"\\nSuma Pagado por a√±o (usando Fecha):\\n\", by_year_fecha.tail(6))\n",
    "    print(\"\\nSuma Pagado por a√±o (usando Fec_Estado):\\n\", by_year_fest.tail(6))\n",
    "\n",
    "    print(\"\\nTop Estado con pago>0:\\n\", estado[pag>0].value_counts().head(10))\n",
    "\n",
    "    mask_2025_fest = fec_estado.dt.year.eq(2025)\n",
    "    print(\"\\n2025 por Fec_Estado ‚Üí filas con pago>0:\", int((pag[mask_2025_fest]>0).sum()),\n",
    "        \" | suma:\", float(pag[mask_2025_fest].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ea8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OBSOLETO: bloque V1, no ejecutar ---\n",
    "if False:\n",
    "    pass\n",
    "\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "\n",
    "    ROOT = Path.cwd().parent if Path.cwd().name==\"notebooks\" else Path.cwd()\n",
    "    dfp = pd.read_csv(ROOT/\"data\"/\"raw\"/\"ETL_vPrestaciones (2).csv\", low_memory=False)\n",
    "\n",
    "    def top_vals(s, n=20):\n",
    "        return (s.astype(str).str.strip().str.upper()\n",
    "                .replace({'': '(VAC√çO)', 'NAN': '(NULO)'})\n",
    "                .value_counts().head(n))\n",
    "\n",
    "    print(\">>> TOP valores 'Pagado':\")\n",
    "    print(top_vals(dfp['Pagado']))\n",
    "\n",
    "    print(\"\\n>>> TOP valores 'Estado':\")\n",
    "    print(top_vals(dfp['Estado']))\n",
    "\n",
    "    print(\"\\nMuestra cruda Pagado (primeras 10 celdas):\")\n",
    "    print(dfp['Pagado'].head(10).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ea79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OBSOLETO: bloque V1, no ejecutar ---\n",
    "if False:\n",
    "    pass\n",
    "\n",
    "    # KPIs 2025 basados en Pagado (booleano) ‚Äî conteos por paciente\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "    dfp = pd.read_csv(ROOT / \"data\" / \"raw\" / \"ETL_vPrestaciones (2).csv\", low_memory=False)\n",
    "\n",
    "    # --- Parse de fechas\n",
    "    fecha      = pd.to_datetime(dfp.get('Fecha'), errors='coerce', dayfirst=True)\n",
    "    fec_estado = pd.to_datetime(dfp.get('Fec_Estado'), errors='coerce', dayfirst=True)\n",
    "\n",
    "    # A√±o/mes de \"presupuesto/registro\" y de \"pago\"\n",
    "    anio_ppto = fecha.dt.year\n",
    "    mes_ppto  = fecha.dt.month\n",
    "\n",
    "    anio_pago = fec_estado.dt.year.fillna(anio_ppto)  # si no hay Fec_Estado, caer a Fecha\n",
    "    mes_pago  = fec_estado.dt.month.fillna(mes_ppto)\n",
    "\n",
    "    # --- Pagado como booleano robusto\n",
    "    pag_bool = (dfp['Pagado']\n",
    "                .astype(str).str.strip().str.upper()\n",
    "                .map({'TRUE': True, 'FALSE': False})\n",
    "                .fillna(False))\n",
    "\n",
    "    # --- Montos de referencia del \"presupuesto\" (solo para identificar que hay registro)\n",
    "    m_ppto = None\n",
    "    for cand in ['Valor_Total', 'Precio_Total', 'Valor_Prest', 'Precio']:\n",
    "        if cand in dfp.columns:\n",
    "            m_ppto = cand\n",
    "            break\n",
    "\n",
    "    if m_ppto is None:\n",
    "        # Si no hay montos, usamos la mera existencia de filas como \"registro de ppto\"\n",
    "        tiene_ppto_2025 = anio_ppto.eq(2025)\n",
    "    else:\n",
    "        # Consideramos \"ppto\" si el monto es > 0\n",
    "        monto = pd.to_numeric(dfp[m_ppto], errors='coerce')\n",
    "        tiene_ppto_2025 = anio_ppto.eq(2025) & (monto > 0)\n",
    "\n",
    "    # --- Flags 2025\n",
    "    tiene_pago_2025 = anio_pago.eq(2025) & pag_bool\n",
    "\n",
    "    # --- KPIs por PACIENTE\n",
    "    rut_col = 'RUT' if 'RUT' in dfp.columns else 'RutBeneficiario'\n",
    "    assert rut_col in dfp.columns, \"No encuentro columna de RUT para identificar pacientes.\"\n",
    "\n",
    "    pacientes_ppto_2025 = dfp.loc[tiene_ppto_2025, rut_col].dropna().astype(str).nunique()\n",
    "    pacientes_pago_2025 = dfp.loc[tiene_pago_2025, rut_col].dropna().astype(str).nunique()\n",
    "\n",
    "    # Serie mensual (n¬∞ pacientes √∫nicos por mes)\n",
    "    serie_ppto = (dfp.loc[tiene_ppto_2025, [rut_col]]\n",
    "                    .assign(_mes=mes_ppto[tiene_ppto_2025].astype('Int64'))\n",
    "                    .dropna()\n",
    "                    .drop_duplicates()\n",
    "                    .groupby('_mes')[rut_col].nunique()\n",
    "                    .reindex(range(1,13), fill_value=0))\n",
    "\n",
    "    serie_pago = (dfp.loc[tiene_pago_2025, [rut_col]]\n",
    "                    .assign(_mes=mes_pago[tiene_pago_2025].astype('Int64'))\n",
    "                    .dropna()\n",
    "                    .drop_duplicates()\n",
    "                    .groupby('_mes')[rut_col].nunique()\n",
    "                    .reindex(range(1,13), fill_value=0))\n",
    "\n",
    "    # Top convenios entre quienes pagaron en 2025\n",
    "    if 'Convenio' in dfp.columns:\n",
    "        top_conv_pago = (dfp.loc[tiene_pago_2025, ['RUT','Convenio']]\n",
    "                        .dropna()\n",
    "                        .drop_duplicates('RUT')['Convenio']\n",
    "                        .astype(str).str.upper()\n",
    "                        .value_counts().head(10))\n",
    "    else:\n",
    "        top_conv_pago = pd.Series(dtype='int64')\n",
    "\n",
    "    kpis_bool = {\n",
    "        'pacientes_ppto_creado_2025': int(pacientes_ppto_2025),\n",
    "        'pacientes_con_abono_2025'  : int(pacientes_pago_2025),\n",
    "        'tasa_pacientes_con_abono'  : (int(pacientes_pago_2025) / int(pacientes_ppto_2025)) if pacientes_ppto_2025 else np.nan,\n",
    "    }\n",
    "\n",
    "    print(\"KPIs 2025 (conteos por paciente, Pagado booleano):\", kpis_bool)\n",
    "    print(\"\\nPacientes con ppto por mes (2025):\\n\", serie_ppto)\n",
    "    print(\"\\nPacientes con abono por mes (2025):\\n\", serie_pago)\n",
    "    print(\"\\nTop convenios (pacientes que pagaron en 2025):\\n\", top_conv_pago)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chequeo Titular vs Beneficiario (opcional) ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "CLIENTES_PATH = ROOT / \"data\" / \"raw\" / \"Tab_Clientes(2).csv\"\n",
    "if CLIENTES_PATH.exists():\n",
    "    dfc = pd.read_csv(CLIENTES_PATH, low_memory=False)\n",
    "    if {'RutTitular','RutBeneficiario'}.issubset(dfc.columns):\n",
    "        a = dfc['RutTitular'].astype(str)\n",
    "        b = dfc['RutBeneficiario'].astype(str)\n",
    "        prop_iguales = (a == b).mean()\n",
    "        print(\"Proporci√≥n titular == beneficiario:\", round(prop_iguales, 3))\n",
    "\n",
    "        dist = (dfc.groupby('RutTitular')['RutBeneficiario']\n",
    "                  .nunique().describe(percentiles=[.5,.9,.95]))\n",
    "        print(\"Beneficiarios distintos por titular (describe):\\n\", dist)\n",
    "    else:\n",
    "        print(\"No est√°n ambas columnas en Clientes.\")\n",
    "else:\n",
    "    print(\"No encuentro\", CLIENTES_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === QA AUTOCONTENIDO: carga, parsing y pruebas de alineaci√≥n ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "PREST_PATH = ROOT / \"data\" / \"raw\" / \"ETL_vPrestaciones (2).csv\"\n",
    "assert PREST_PATH.exists(), f\"No encuentro: {PREST_PATH}\"\n",
    "\n",
    "# --- Carga base de Prestaciones\n",
    "dfp = pd.read_csv(PREST_PATH, low_memory=False)\n",
    "\n",
    "# Columnas clave (robustas a may√∫sculas/min√∫sculas)\n",
    "cols = {c.lower(): c for c in dfp.columns}\n",
    "rut_col     = cols.get('rut', 'RUT' if 'RUT' in dfp.columns else None)\n",
    "fecha_col   = cols.get('fecha', 'Fecha' if 'Fecha' in dfp.columns else None)\n",
    "fecest_col  = cols.get('fec_estado', 'Fec_Estado' if 'Fec_Estado' in dfp.columns else None)\n",
    "estado_col  = cols.get('estado', 'Estado' if 'Estado' in dfp.columns else None)\n",
    "pagado_col  = cols.get('pagado', 'Pagado' if 'Pagado' in dfp.columns else None)\n",
    "ot_col      = cols.get('ot', 'OT' if 'OT' in dfp.columns else None)\n",
    "\n",
    "needed = [rut_col, fecha_col, estado_col, pagado_col]\n",
    "assert all(x in dfp.columns for x in needed), f\"Faltan columnas m√≠nimas: {needed}\"\n",
    "\n",
    "# --- Parseo de fechas\n",
    "dfp['_fecha']     = pd.to_datetime(dfp[fecha_col], errors='coerce', dayfirst=True)\n",
    "dfp['_fecestado'] = pd.to_datetime(dfp.get(fecest_col), errors='coerce', dayfirst=True) if fecest_col in dfp.columns else pd.NaT\n",
    "\n",
    "# --- A√±os derivados\n",
    "dfp['_anio_fecha']     = dfp['_fecha'].dt.year\n",
    "dfp['_anio_fecestado'] = dfp['_fecestado'].dt.year\n",
    "\n",
    "# --- Booleano de pago desde 'Pagado' (TRUE/FALSE u otras variantes)\n",
    "def to_bool(x):\n",
    "    if pd.isna(x): return False\n",
    "    s = str(x).strip().upper()\n",
    "    if s in {'TRUE','1','SI','S√ç','YES'}: return True\n",
    "    if s in {'FALSE','0','NO'}: return False\n",
    "    return False\n",
    "\n",
    "dfp['_pag_bool'] = dfp[pagado_col].map(to_bool)\n",
    "\n",
    "# --- QA-1: ‚Äúppto 2025‚Äù solo en ciertos ESTADOS (DIAGNOSTICADA/INICIADA)\n",
    "estados_ppto = {\"DIAGNOSTICADA\", \"INICIADA\"}\n",
    "mask_ppto_2025 = (dfp['_anio_fecha'] == 2025) & (dfp[estado_col].astype(str).str.upper().isin(estados_ppto))\n",
    "p_pp_to = dfp.loc[mask_ppto_2025, rut_col].dropna().astype(str).nunique()\n",
    "print(\"Pacientes ppto 2025 (solo estados DIAGNOSTICADA/INICIADA):\", p_pp_to)\n",
    "\n",
    "# --- QA-2: ¬øy si cuentan OT (√≥rdenes) en vez de paciente?\n",
    "if ot_col in dfp.columns:\n",
    "    ot_ppto_2025 = dfp.loc[dfp['_anio_fecha'] == 2025, ot_col].dropna().astype(str).nunique()\n",
    "    # pagos en 2025 por Fec_Estado + Pagado True\n",
    "    mask_pago_2025 = (dfp['_anio_fecestado'] == 2025) & (dfp['_pag_bool'])\n",
    "    ot_pago_2025 = dfp.loc[mask_pago_2025, ot_col].dropna().astype(str).nunique()\n",
    "    print(\"OT con ppto 2025:\", ot_ppto_2025, \" | OT con pago 2025:\", ot_pago_2025)\n",
    "else:\n",
    "    print(\"No hay columna OT en Prestaciones; QA-2 no aplica.\")\n",
    "\n",
    "# --- (Extra) Tus m√©tricas ‚Äúpor paciente‚Äù para comparar r√°pidamente:\n",
    "pac_ppto_2025 = dfp.loc[dfp['_anio_fecha'] == 2025, rut_col].dropna().astype(str).nunique()\n",
    "pac_pago_2025 = dfp.loc[(dfp['_anio_fecestado'] == 2025) & dfp['_pag_bool'], rut_col].dropna().astype(str).nunique()\n",
    "print(\"Paciente √∫nico: ppto_2025 =\", pac_ppto_2025, \" | pago_2025 =\", pac_pago_2025)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Generar Gu√≠a de Mejora de Datos: .md -> .html -> (opcional) .pdf ===\n",
    "\n",
    "from pathlib import Path               # Manejo seguro de rutas multiplataforma\n",
    "import textwrap                        # Para quitar indentaciones indeseadas\n",
    "import datetime as dt                  # Para sellar fecha si quieres\n",
    "import sys                             # Para detectar si hay m√≥dulos opcionales\n",
    "\n",
    "# 1) Definimos ROOT (igual que en tus notebooks: sube un nivel desde /notebooks)\n",
    "ROOT = Path.cwd().parent               # Carpeta ra√≠z del proyecto\n",
    "reports_dir = ROOT / \"reports\"         # Carpeta p√∫blica de reportes\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)  # Crea /reports si no existe\n",
    "\n",
    "# 2) Definimos rutas de salida para los archivos\n",
    "md_path   = reports_dir / \"guia_mejora_datos.md\"   # Archivo markdown final\n",
    "html_path = reports_dir / \"guia_mejora_datos.html\" # Export en HTML\n",
    "pdf_path  = reports_dir / \"guia_mejora_datos.pdf\"  # Export en PDF (opcional)\n",
    "\n",
    "# 3) Contenido Markdown (pegamos el bloque que te pas√© arriba)\n",
    "md_content = \"\"\"\n",
    "# Gu√≠a de Mejora de Datos ‚Äî Portal Ortodoncia\n",
    "**Fecha:** 06-sep-2025  \n",
    "**Autor:** Santiago Tupper  \n",
    "**Contexto:** Proyecto de segmentaci√≥n de pacientes con clustering (K=3) ‚Äî foco en reproducibilidad, interpretabilidad y privacidad.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Objetivo\n",
    "Alinear reglas y prioridades para **mejorar la calidad de datos** que alimenta el an√°lisis (Tab_Clientes y Prestaciones), con el fin de:\n",
    "- aumentar la confiabilidad de m√©tricas (p. ej., % cumplimiento, recencia),\n",
    "- facilitar segmentaciones accionables (retenci√≥n, reactivaci√≥n, depuraci√≥n),\n",
    "- y reducir retrabajo entre 'dashboard.pbix' y Analytics.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Alcance\n",
    "- **Incluye:** Fechas (hist√≥rico vs planificaci√≥n), `DiasDesdeUltimaVisita`, KPIs de presupuesto, presencias 15d‚Äì6m, geograf√≠a (Comuna/Regi√≥n), Empresa/Convenio, v√≠nculo ppto‚Üîpago (Prestaciones).\n",
    "- **No incluye (por ahora):** detalle cl√≠nico por prestaci√≥n, rendimiento por profesional, costos.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Hallazgos de calidad (resumen)\n",
    "**Fechas**\n",
    "- Hist√≥rico en ISO; planificaci√≥n en **DD/MM/AAAA** con **fechas futuras** (baja incidencia).  \n",
    "- Se crearon flags de planificaci√≥n y `dias_hasta` (mediana ‚âà 65 d√≠as; m√°x ‚âà 114).  \n",
    "- Acci√≥n: mantener doble parsing y flags; consolidar diccionario de campos fecha.\n",
    "\n",
    "**`DiasDesdeUltimaVisita`**\n",
    "- Validado vs rec√°lculo; **offset sistem√°tico +11 d√≠as** (100% positivo en distribuci√≥n).  \n",
    "- Decisi√≥n: usar el **valor del sistema** y documentar offset; revisar origen junto a TI.\n",
    "\n",
    "**KPIs de presupuestos**\n",
    "- Colas largas (outliers) en montos ‚Üí se usa **`log1p`**.  \n",
    "- `TicketPromPpto` incluido; **NaN‚Üí0 solo para el modelo** (interpretaci√≥n ‚Äúsin actividad‚Äù).  \n",
    "- Acci√≥n: estandarizar reglas de KPIs y denominadores protegidos.\n",
    "\n",
    "**Presencias de atenci√≥n (uso real)**\n",
    "- Ventanas con mejor se√±al: **15d, 1m, 3m, 6m**.  \n",
    "- Acci√≥n: mantener solo estas cuatro; descartar 1a/2a en el set de modelado.\n",
    "\n",
    "**Geograf√≠a**\n",
    "- `Comuna_grp` (Top-N + Otras/Infreq + Sin Comuna) y `Region` con dummies.  \n",
    "- >95% de pacientes en **Regi√≥n Metropolitana**; C2 tiene **registros incompletos** (Sin Regi√≥n 30%).  \n",
    "- Acci√≥n: reforzar captura de Regi√≥n/Comuna y mapeo maestro.\n",
    "\n",
    "**Empresa/Convenio**\n",
    "- Cobertura desigual; **no aport√≥ separaci√≥n adicional** en clustering (A/B).  \n",
    "- Acci√≥n: mantener como metadato; no forzar su uso en el modelo si no mejora calidad.\n",
    "\n",
    "**Prestaciones (cohortes 2025)**\n",
    "- ppto=4.564, pago=4.862, ambos=3.951 ‚Üí **tasa 91%**.  \n",
    "- Acci√≥n: fijar reglas de estados v√°lidos (DIAGNOSTICADA/INICIADA) y consistencia ppto‚ÜîOT.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Reglas acordadas (versi√≥n aplicable)\n",
    "- **Fechas:** parseo dual (ISO vs DD/MM/AAAA) + flags de planificaci√≥n; conservar `dias_hasta`.  \n",
    "- **DiasDesdeUltimaVisita:** usar valor del sistema; registrar offset +11 en documentaci√≥n t√©cnica.  \n",
    "- **KPIs:** `log1p` en montos; salvaguardas de denominador; `NaN‚Üí0` solo para features de modelado.  \n",
    "- **Ventanas:** solo presencias **15d, 1m, 3m, 6m**.  \n",
    "- **Geograf√≠a:** mantener `Comuna_grp` y `Region` (one-hot); controlar ‚ÄúSin Comuna/Regi√≥n‚Äù.  \n",
    "- **Empresa/Convenio:** no se usa para separar clusters (respaldo A/B); se conserva como contexto.  \n",
    "- **Prestaciones:** cohortes por a√±o; estados v√°lidos DIAGNOSTICADA/INICIADA; controles ppto‚ÜîOT.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Recomendaciones priorizadas\n",
    "| Prioridad | Recomendaci√≥n | Detalle | √âxito (c√≥mo se mide) |\n",
    "|---|---|---|---|\n",
    "| **MUST** | Normalizar fechas | Diccionario de campos + validaci√≥n autom√°tica de formato | 0% errores de parseo; flags coherentes |\n",
    "| **MUST** | Revisar origen de offset +11 d√≠as | Revisi√≥n con TI del c√°lculo de `DiasDesdeUltimaVisita` | Offset documentado/ajustado |\n",
    "| **MUST** | Estandarizar KPIs | Reglas compartidas con 'dashboard.pbix' (denominadores, `log1p`) | Discrepancias < ¬±1% |\n",
    "| **SHOULD** | Completar geograf√≠a | Reducci√≥n de ‚ÄúSin Comuna/Regi√≥n‚Äù; maestro de comunas | <2% ‚ÄúSin Comuna/Regi√≥n‚Äù |\n",
    "| **SHOULD** | Consolidar v√≠nculo ppto‚Üîpago | QA por OT y por paciente/a√±o | Consistencias > 98% |\n",
    "| **COULD** | Reevaluar Empresa/Convenio | Mejoras de calidad + nueva A/B | S√≥lo se usa si mejora m√©tricas |\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Roadmap sugerido\n",
    "1. **Semana 1‚Äì2:** Normalizaci√≥n de fechas y documentaci√≥n del offset de `DiasDesdeUltimaVisita`.  \n",
    "2. **Semana 3:** Reglas de KPIs consensuadas entre Analytics y 'dashboard.pbix' (one-pager).  \n",
    "3. **Semana 4‚Äì5:** Limpieza geogr√°fica y maestro de comunas/regiones.  \n",
    "4. **Semana 6:** QA ppto‚Üîpago (Prestaciones) y reporte de consistencia.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) M√©tricas de √©xito\n",
    "- Errores de parseo de fechas = 0%.  \n",
    "- Discrepancia de KPIs ('dashboard.pbix' vs Analytics) < ¬±1%.  \n",
    "- ‚ÄúSin Regi√≥n/Comuna‚Äù < 2%.  \n",
    "- Consistencia ppto‚Üîpago > 98%.  \n",
    "- Trazabilidad reproducible de IDs (RutBeneficiario, RutTitular).\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Anexos\n",
    "- **Metodolog√≠a:** pipeline mixto de escalado (Standard/Robust/passthrough).  \n",
    "- **Clustering:** K=3; baseline basta (Empresa no agrega separaci√≥n).  \n",
    "- **Archivos relacionados:**  \n",
    "  - `/reports/nb04_insights_executive.pdf`  \n",
    "  - `/reports/nb04_dashboard_vs_clustering.csv`  \n",
    "  - `/reports/nb06_prestaciones_validacion.csv`\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "# 4) Guardamos el .md con el contenido anterior\n",
    "md_path.write_text(textwrap.dedent(md_content), encoding=\"utf-8\")  # Quita indentaci√≥n y guarda UTF-8\n",
    "print(f\"[OK] Markdown guardado en: {md_path}\")\n",
    "\n",
    "# 5) Convertimos Markdown -> HTML (usando la librer√≠a est√°ndar 'markdown' si est√° instalada)\n",
    "try:\n",
    "    import markdown  # Intentamos usar 'markdown' (pip install markdown)\n",
    "    html_body = markdown.markdown(md_path.read_text(encoding=\"utf-8\"), extensions=[\"tables\"])  # Soporta tablas\n",
    "except Exception as e:\n",
    "    # Si no est√° instalada, dejamos el contenido envuelto en <pre> para no bloquear el flujo\n",
    "    print(\"[WARN] Paquete 'markdown' no disponible. Generar√© HTML b√°sico de emergencia.\")\n",
    "    raw = md_path.read_text(encoding=\"utf-8\")\n",
    "    html_body = f\"<pre>{raw}</pre>\"\n",
    "\n",
    "# 6) Envolvemos el HTML en una plantilla sencilla (CSS m√≠nimo legible)\n",
    "html_template = f\"\"\"<!doctype html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<title>Gu√≠a de Mejora de Datos ‚Äî Portal Ortodoncia</title>\n",
    "<style>\n",
    " body {{ font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Arial, \"Helvetica Neue\", sans-serif; line-height: 1.45; margin: 40px; }}\n",
    " h1,h2,h3 {{ margin-top: 1.2em; }}\n",
    " code, pre {{ background: #f6f8fa; padding: 2px 4px; border-radius: 4px; }}\n",
    " table {{ border-collapse: collapse; width: 100%; margin: 1em 0; }}\n",
    " th, td {{ border: 1px solid #ddd; padding: 8px; }}\n",
    " th {{ background: #fafafa; }}\n",
    " hr {{ border: none; border-top: 1px solid #eee; margin: 24px 0; }}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "{html_body}\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "# 7) Guardamos el .html final\n",
    "html_path.write_text(html_template, encoding=\"utf-8\")\n",
    "print(f\"[OK] HTML guardado en: {html_path}\")\n",
    "\n",
    "# 8) (Opcional) HTML -> PDF con pdfkit + wkhtmltopdf si est√° disponible\n",
    "try:\n",
    "    import pdfkit  # Requiere: pip install pdfkit  y tener 'wkhtmltopdf' instalado en el sistema\n",
    "    pdfkit.from_file(str(html_path), str(pdf_path))\n",
    "    print(f\"[OK] PDF exportado en: {pdf_path}\")\n",
    "except Exception as e:\n",
    "    # Si no se puede generar el PDF autom√°ticamente, damos una instrucci√≥n clara\n",
    "    print(\"[INFO] No se pudo generar el PDF autom√°ticamente.\")\n",
    "    print(\"      - Opci√≥n A: instala dependencias y reintenta:\")\n",
    "    print(\"        pip install markdown pdfkit\")\n",
    "    print(\"        Instala 'wkhtmltopdf' (macOS: brew install wkhtmltopdf)\")\n",
    "    print(\"      - Opci√≥n B: abre el HTML y usa 'Imprimir' -> 'Guardar como PDF'.\")\n",
    "    print(f\"      HTML listo en: {html_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ab446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
