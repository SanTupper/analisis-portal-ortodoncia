{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 · Preparación de features (activos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0d9c21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. KPIs presupuestos\n",
        "df_kpis = crear_kpis_pptos(df)\n",
        "\n",
        "cols_preview = [\n",
        "    'CantPptos','TotPptos','CantPptosAbo','TotPptosAbo','CantPptosAvan','TotPptosAvan',\n",
        "    'TicketPromPpto','PctPptosAbonados','PctPptosAvanzados','PctCumplimiento','MontoAbonadoProm'\n",
        "]\n",
        "[df for df in cols_preview if df in df_kpis.columns], df_kpis[cols_preview].head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48203c38",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.2 Comprobación general\n",
        "cols = ['CantPptos','TotPptos','CantPptosAbo','TotPptosAbo','CantPptosAvan','TotPptosAvan',\n",
        "        'TicketPromPpto','PctPptosAbonados','PctPptosAvanzados','PctCumplimiento','MontoAbonadoProm']\n",
        "\n",
        "# 1) ¿Cuántos tienen actividad de presupuestos?\n",
        "print(\"Proporción con CantPptos notna:\", df_kpis['CantPptos'].notna().mean())\n",
        "print(\"Proporción con CantPptos > 0 :\", (pd.to_numeric(df_kpis['CantPptos'], errors='coerce') > 0).mean())\n",
        "\n",
        "# 2) Muestra SOLO pacientes con presupuesto (>0) para ver KPIs calculados\n",
        "mask_act = pd.to_numeric(df_kpis['CantPptos'], errors='coerce') > 0\n",
        "df_kpis.loc[mask_act, cols].sample(5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdca131f",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Transformación log1p de montos\n",
        "\n",
        "# columnas de montos a transformar\n",
        "montos = ['TotPptos', 'TotPptosAbo', 'TotPptosAvan']\n",
        "\n",
        "df_m = df_kpis.copy()\n",
        "\n",
        "# asegurar numérico y limpiar negativos (si los hay) -> NaN\n",
        "for c in montos:\n",
        "    if c in df_m.columns:\n",
        "        df_m[c] = pd.to_numeric(df_m[c], errors='coerce')\n",
        "        df_m.loc[df_m[c] < 0, c] = np.nan  # salvaguarda\n",
        "\n",
        "# crear columnas transformadas con log1p\n",
        "for c in montos:\n",
        "    if c in df_m.columns:\n",
        "        df_m[c + '_l1p'] = np.log1p(df_m[c])\n",
        "\n",
        "# (opcional) transformar el ticket promedio si lo vas a usar en el modelo\n",
        "if 'TicketPromPpto' in df_m.columns:\n",
        "    df_m['TicketPromPpto_l1p'] = np.log1p(df_m['TicketPromPpto'])\n",
        "\n",
        "# diagnóstico rápido: percentiles antes / después\n",
        "def resumen_percentiles(serie):\n",
        "    q = serie.quantile([0, .5, .9, .95, .99], interpolation='linear')\n",
        "    q.index = ['min','p50','p90','p95','p99']\n",
        "    return q\n",
        "\n",
        "diag = {}\n",
        "for c in montos:\n",
        "    if c in df_m.columns and (c + '_l1p') in df_m.columns:\n",
        "        diag[c] = pd.DataFrame({\n",
        "            'original': resumen_percentiles(df_m[c].dropna()),\n",
        "            'log1p': resumen_percentiles(df_m[c + '_l1p'].dropna())\n",
        "        })\n",
        "\n",
        "# mostrar resumen\n",
        "for c, tabla in diag.items():\n",
        "    print(f\"\\n==== {c} ====\")\n",
        "    display(tabla)\n",
        "\n",
        "# vistazo de columnas creadas\n",
        "cols_show = [c for c in df_m.columns if c.endswith('_l1p')][:6]\n",
        "print(\"\\nColumnas l1p creadas (ejemplo):\", cols_show)\n",
        "df_m[montos + cols_show].sample(5, random_state=7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "992b2cf4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Cobertura de salud unificada\n",
        "df_m = unificar_cobertura_salud(df_m)\n",
        "df_m['CoberturaSalud'].value_counts(dropna=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ae3ca8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Marcación de activos (≤ 730 días)\n",
        "mask_act = marcar_activos(df_m, dias_umbral=730)\n",
        "df_act = df_m[mask_act].copy()\n",
        "df_inact = df_m[~mask_act].copy()\n",
        "df_act.shape, df_inact.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "525492b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 Sanity check de activos (corregido)\n",
        "\n",
        "n_total = len(df_m)\n",
        "n_act = len(df_act)\n",
        "n_inact = len(df_inact)\n",
        "\n",
        "print(\"Total:\", n_total, \" | Activos:\", n_act, \" | Inactivos:\", n_inact)\n",
        "print(\"Proporción activos:\", round(n_act/n_total*100, 2), \"%\")\n",
        "\n",
        "# Detectar columnas de atención (evitar las _pres)\n",
        "ventanas = [c for c in df_m.columns if c.lower().startswith('atencion') and not c.endswith('_pres')]\n",
        "print(\"Ventanas detectadas:\", ventanas)\n",
        "\n",
        "if ventanas:\n",
        "    # Convertir columna por columna a numérico\n",
        "    vnum = df_m[ventanas].apply(pd.to_numeric, errors='coerce')\n",
        "    # Presencia por fila: ¿alguna ventana > 0?\n",
        "    cualquier_atencion = vnum.fillna(0).gt(0).any(axis=1)\n",
        "else:\n",
        "    cualquier_atencion = pd.Series(False, index=df_m.index, name='cualquier_atencion')\n",
        "\n",
        "# Regla oficial por días\n",
        "dias = pd.to_numeric(df_m.get('DiasDesdeUltimaVisita'), errors='coerce')\n",
        "por_dias = dias.le(730).fillna(False)\n",
        "\n",
        "print(\"Activos por ventanas de atención:\", int(cualquier_atencion.sum()))\n",
        "print(\"Activos por días <= 730:\", int(por_dias.sum()))\n",
        "\n",
        "# Diferencia entre criterios (solo diagnóstico)\n",
        "diff_rate = (por_dias.astype(int) - cualquier_atencion.astype(int)).abs().mean()\n",
        "print(\"Diferencia relativa entre criterios:\", round(100*diff_rate, 2), \"%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc70afbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Presencia de atención (ventanas 15d, 1m, 3m, 6m, 1a, 2a)\n",
        "\n",
        "# Ventanas a usar (presencia 0/1)\n",
        "ventanas_keep = ['Atencion15d','Atencion1m','Atencion3m','Atencion6m','Atencion1a','Atencion2a']\n",
        "\n",
        "df_act = df_act.copy()\n",
        "\n",
        "# Crear columnas *_pres\n",
        "creadas = []\n",
        "for v in ventanas_keep:\n",
        "    if v in df_act.columns:\n",
        "        # >0 => 1, NaN/<=0 => 0\n",
        "        df_act[v + '_pres'] = (pd.to_numeric(df_act[v], errors='coerce') > 0).astype('uint8')\n",
        "        creadas.append(v + '_pres')\n",
        "\n",
        "print(\"Features de presencia creadas:\", creadas)\n",
        "\n",
        "# Cobertura por ventana (qué % de activos tiene ≥1 atención en esa ventana)\n",
        "cov = df_act[creadas].mean().sort_values(ascending=False)\n",
        "print(\"\\nCobertura (proporción=1) por ventana seleccionada:\\n\", cov)\n",
        "\n",
        "# (opcional) vistazo\n",
        "df_act[['RutBeneficiario'] + creadas].head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb9c57c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1 Depurar presencia: eliminar redundantes (1a y 2a)\n",
        "pres_cols_all = ['Atencion15d_pres','Atencion1m_pres','Atencion3m_pres','Atencion6m_pres',\n",
        "                 'Atencion1a_pres','Atencion2a_pres']\n",
        "keep_pres = ['Atencion15d_pres','Atencion1m_pres','Atencion3m_pres','Atencion6m_pres']\n",
        "\n",
        "# Eliminar las redundantes si existen\n",
        "drop_pres = [c for c in pres_cols_all if c not in keep_pres and c in df_act.columns]\n",
        "df_act = df_act.drop(columns=drop_pres, errors='ignore')\n",
        "\n",
        "print(\"Presencia mantenida:\", [c for c in keep_pres if c in df_act.columns])\n",
        "print(\"Eliminadas:\", drop_pres)\n",
        "\n",
        "# (opcional) sanity rápido\n",
        "print(\"Cobertura final:\\n\", df_act[keep_pres].mean().sort_values(ascending=False).round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4d3f01",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Geografía para modelar — Top-20 a partir de TODA la base (df) + whitelist de comunas clave\n",
        "\n",
        "def _clean_comuna(s: pd.Series) -> pd.Series:\n",
        "    s = s.astype(str).str.strip()\n",
        "    return s.replace({'nan':'Sin Comuna','None':'Sin Comuna','':'Sin Comuna'})\n",
        "\n",
        "# 6.0 Limpieza estándar\n",
        "df_all = df.copy()\n",
        "df_all['Comuna_clean'] = _clean_comuna(df_all.get('Comuna', pd.Series(index=df_all.index)))\n",
        "df_act = df_act.copy()\n",
        "df_act['Comuna_clean'] = _clean_comuna(df_act.get('Comuna', pd.Series(index=df_act.index)))\n",
        "\n",
        "# 6.1 Top-20 global (sobre TODA la base)\n",
        "topN = 20\n",
        "top_global = df_all['Comuna_clean'].value_counts().head(topN).index.tolist()\n",
        "\n",
        "# 6.2 Whitelist (comunas que DEBEN quedar como categoría propia aunque no queden top en activos)\n",
        "whitelist = {'Iquique'}  # agrega otras si negocio lo pide, p.ej.: {'Iquique','Providencia'}\n",
        "\n",
        "# 6.3 Lista final de categorías propias\n",
        "categorias_propias = sorted(set(top_global).union(whitelist).union({'Sin Comuna'}))\n",
        "\n",
        "# 6.4 Aplicar mapeo al subset de activos\n",
        "def map_comuna_grp(val: str) -> str:\n",
        "    return val if val in categorias_propias else 'Otras/Infreq'\n",
        "\n",
        "df_act['Comuna_grp'] = df_act['Comuna_clean'].map(map_comuna_grp)\n",
        "\n",
        "# 6.5 Región limpia\n",
        "if 'Region' in df_act.columns:\n",
        "    df_act['Region'] = (df_act['Region'].astype(str).str.strip()\n",
        "                        .replace({'nan':'Sin Región','None':'Sin Región','':'Sin Región'}))\n",
        "else:\n",
        "    df_act['Region'] = 'Sin Región'\n",
        "\n",
        "# 6.6 Tabla para revisar\n",
        "top_tab = (df_act['Comuna_grp'].value_counts()\n",
        "           .to_frame('n')\n",
        "           .assign(pct=lambda d: (d['n']/len(df_act)).round(4)))\n",
        "print(\"Top categorías en Comuna_grp (activos, con top global + whitelist):\")\n",
        "display(top_tab.head(25))\n",
        "\n",
        "# 6.7 Dummies\n",
        "df_act_dum = pd.get_dummies(df_act, columns=['Comuna_grp','Region'], drop_first=False, dtype='uint8')\n",
        "dum_cols = [c for c in df_act_dum.columns if c.startswith('Comuna_grp_') or c.startswith('Region_')]\n",
        "print(\"Total dummies geográficas creadas:\", len(dum_cols))\n",
        "print(\"Ejemplo:\", dum_cols[:12])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f6c0cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6b. Empresa/Convenio (features)\n",
        "import pandas as pd, unicodedata, re\n",
        "\n",
        "def _norm_text_series(s: pd.Series) -> pd.Series:\n",
        "    s = s.astype(str).fillna('').str.strip()\n",
        "    def _norm_one(x: str) -> str:\n",
        "        x = unicodedata.normalize('NFKD', x)\n",
        "        x = ''.join(c for c in x if not unicodedata.combining(c))\n",
        "        return x.upper()\n",
        "    return s.apply(_norm_one)\n",
        "\n",
        "df_act = df_act.copy()\n",
        "col_emp = 'Empresa'\n",
        "if col_emp not in df_act.columns:\n",
        "    df_act[col_emp] = ''\n",
        "\n",
        "# Normalizar texto\n",
        "df_act['Empresa_clean'] = _norm_text_series(df_act[col_emp])\n",
        "df_act['Empresa_clean'] = df_act['Empresa_clean'].replace({'NAN':'', 'NONE':'', 'NULL':'', '0':''})\n",
        "df_act['Empresa_clean'] = df_act['Empresa_clean'].replace('', 'SIN EMPRESA')\n",
        "\n",
        "# Flags: tiene empresa / es convenio\n",
        "df_act['TieneEmpresa'] = (df_act['Empresa_clean'] != 'SIN EMPRESA').astype('uint8')\n",
        "df_act['EsConvenio']   = df_act['Empresa_clean'].str.contains(r'CONV|CONVENIO', regex=True).astype('uint8')\n",
        "\n",
        "# Agrupar empresas: Top-15 + SIN EMPRESA + OTRAS/INFREQ\n",
        "top_k = 15\n",
        "vc_emp = df_act['Empresa_clean'].value_counts()\n",
        "top_emp = vc_emp[vc_emp.index != 'SIN EMPRESA'].head(top_k).index.tolist()\n",
        "\n",
        "def _map_emp(x: str) -> str:\n",
        "    if x == 'SIN EMPRESA':\n",
        "        return 'SIN EMPRESA'\n",
        "    return x if x in top_emp else 'OTRAS/INFREQ'\n",
        "\n",
        "df_act['Empresa_grp'] = df_act['Empresa_clean'].map(_map_emp)\n",
        "\n",
        "# Tabla de control\n",
        "emp_tab = (df_act['Empresa_grp'].value_counts()\n",
        "           .to_frame('n')\n",
        "           .assign(pct=lambda d: (d['n']/len(df_act)).round(4)))\n",
        "print(\"Top Empresa_grp (activos):\")\n",
        "display(emp_tab.head(25))\n",
        "\n",
        "# Incorporar a df_act_dum y hacer one-hot de Empresa_grp\n",
        "df_act_dum = df_act_dum.copy()\n",
        "for col in ['TieneEmpresa','EsConvenio','Empresa_grp']:\n",
        "    df_act_dum[col] = df_act[col].values\n",
        "\n",
        "df_act_dum = pd.get_dummies(df_act_dum, columns=['Empresa_grp'], drop_first=False, dtype='uint8')\n",
        "\n",
        "dum_emp = [c for c in df_act_dum.columns if c.startswith('Empresa_grp_')]\n",
        "print(\"Dummies Empresa creadas:\", len(dum_emp))\n",
        "print(\"Ejemplos:\", dum_emp[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30fccb1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "dum_comuna = [c for c in df_act_dum.columns if c.startswith('Comuna_grp_')]\n",
        "dum_region = [c for c in df_act_dum.columns if c.startswith('Region_')]\n",
        "print(\"Dummies Comuna_grp:\", len(dum_comuna))\n",
        "print(\"Dummies Region:\", len(dum_region))\n",
        "print(\"Total dummies geográficas:\", len(dum_comuna) + len(dum_region))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8948cab3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7 (v3). Ensamble del dataset de modelado: baseline y con Empresa/Convenio\n",
        "# Requiere: df_act_dum (con dummies de geografía y, si corresponde, de empresa)\n",
        "\n",
        "df_model = df_act_dum.copy()\n",
        "\n",
        "# --- Selección de columnas ---\n",
        "# Numéricas\n",
        "num_keep = [\n",
        "    'Edad',\n",
        "    'CantPptos', 'CantPptosAbo', 'CantPptosAvan',\n",
        "    'TotPptos_l1p', 'TotPptosAbo_l1p', 'TotPptosAvan_l1p',\n",
        "    'PctCumplimiento', 'TicketPromPpto_l1p'\n",
        "]\n",
        "\n",
        "# Presencias (0/1)\n",
        "pres_keep = [c for c in ['Atencion15d_pres','Atencion1m_pres','Atencion3m_pres','Atencion6m_pres']\n",
        "             if c in df_model.columns]\n",
        "\n",
        "# Dummies geográficas\n",
        "dum_geo = [c for c in df_model.columns if c.startswith('Comuna_grp_') or c.startswith('Region_')]\n",
        "\n",
        "# Señales de Empresa/Convenio\n",
        "bin_emp  = [c for c in ['TieneEmpresa','EsConvenio'] if c in df_model.columns]\n",
        "dum_emp  = [c for c in df_model.columns if c.startswith('Empresa_grp_')]\n",
        "\n",
        "# Robustez: quedarnos solo con las que existen\n",
        "num_keep = [c for c in num_keep if c in df_model.columns]\n",
        "dum_geo  = sorted(dum_geo)\n",
        "dum_emp  = sorted(dum_emp)\n",
        "\n",
        "# --- 2 vistas: BASE (sin empresa) y EMPRESA (con empresa) ---\n",
        "cols_base = num_keep + pres_keep + dum_geo\n",
        "cols_emp  = cols_base + bin_emp + dum_emp\n",
        "\n",
        "X_base = df_model[cols_base].copy()\n",
        "X_emp  = df_model[cols_emp].copy() if cols_emp else None  # por si no hubiera nada de empresa\n",
        "\n",
        "# --- Tipos y limpieza ---\n",
        "def _cast_and_fill(X, num_cols, onehot_cols):\n",
        "    if num_cols:\n",
        "        X[num_cols] = X[num_cols].apply(pd.to_numeric, errors='coerce')\n",
        "    X = X.fillna(0)\n",
        "    for c in onehot_cols:\n",
        "        if c in X.columns:\n",
        "            X[c] = X[c].astype('uint8')\n",
        "    for c in num_cols:\n",
        "        if c in X.columns:\n",
        "            X[c] = pd.to_numeric(X[c], downcast='float')  # float32\n",
        "    return X\n",
        "\n",
        "X_base = _cast_and_fill(X_base, num_keep, pres_keep + dum_geo)\n",
        "if X_emp is not None:\n",
        "    X_emp = _cast_and_fill(X_emp, num_keep, pres_keep + dum_geo + bin_emp + dum_emp)\n",
        "\n",
        "# --- Reporte rápido ---\n",
        "print(\"BASELINE  -> shape:\", X_base.shape, \"| NaNs:\", int(X_base.isna().sum().sum()))\n",
        "if X_emp is not None:\n",
        "    print(\"CON EMP   -> shape:\", X_emp.shape,  \"| NaNs:\", int(X_emp.isna().sum().sum()))\n",
        "else:\n",
        "    print(\"CON EMP   -> no se generó (no hay columnas de empresa/convenio).\")\n",
        "\n",
        "print(\"Grupos (BASE) -> num:\", len(num_keep),\n",
        "      \"| pres:\", len(pres_keep), \"| d_geo:\", len(dum_geo))\n",
        "if X_emp is not None:\n",
        "    print(\"Extra (EMP)  -> bin_emp:\", len(bin_emp), \"| d_emp:\", len(dum_emp))\n",
        "\n",
        "# --- Export ---\n",
        "out_base = ROOT / \"data\" / \"processed\" / \"activos_for_model_v2.csv\"\n",
        "out_base.parent.mkdir(parents=True, exist_ok=True)\n",
        "X_base.to_csv(out_base, index=False, encoding=\"utf-8\")\n",
        "print(\"Exportado BASELINE  →\", out_base.resolve())\n",
        "\n",
        "if X_emp is not None:\n",
        "    out_emp = ROOT / \"data\" / \"processed\" / \"activos_for_model_v2_empresa.csv\"\n",
        "    out_emp.parent.mkdir(parents=True, exist_ok=True)\n",
        "    X_emp.to_csv(out_emp, index=False, encoding=\"utf-8\")\n",
        "    print(\"Exportado CON EMP   →\", out_emp.resolve())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c12b9a12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8 (v2). IDs para reenganchar clusters + trazabilidad (Titular y #beneficiarios)\n",
        "\n",
        "# Base de IDs del set activo (respeta el orden del dataset modelado)\n",
        "ids_v2 = (\n",
        "    df_act[['RutBeneficiario']]\n",
        "    .copy()\n",
        "    .reset_index(drop=True)\n",
        "    .rename_axis('idx_model')\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Enriquecimiento desde Clientes (opcional si existe el archivo)\n",
        "CLI_PATH = ROOT / \"data\" / \"raw\" / \"Tab_Clientes(2).csv\"\n",
        "if CLI_PATH.exists():\n",
        "    dfc = pd.read_csv(CLI_PATH, low_memory=False)\n",
        "    if {'RutBeneficiario','RutTitular'}.issubset(dfc.columns):\n",
        "        # Map RutBeneficiario -> RutTitular (1a coincidencia por beneficiario)\n",
        "        map_titular = (\n",
        "            dfc[['RutBeneficiario','RutTitular']]\n",
        "            .dropna(subset=['RutBeneficiario'])\n",
        "            .drop_duplicates(subset=['RutBeneficiario'])\n",
        "            .set_index('RutBeneficiario')['RutTitular']\n",
        "        )\n",
        "        # Conteo de beneficiarios por titular\n",
        "        ben_por_titular = (\n",
        "            dfc.groupby('RutTitular')['RutBeneficiario']\n",
        "            .nunique()\n",
        "            .rename('Beneficiarios_por_titular')\n",
        "        )\n",
        "        # Enriquecer IDs\n",
        "        ids_v2['RutTitular'] = ids_v2['RutBeneficiario'].map(map_titular)\n",
        "        ids_v2 = ids_v2.merge(ben_por_titular, how='left',\n",
        "                              left_on='RutTitular', right_index=True)\n",
        "    else:\n",
        "        print(\"Aviso: Clientes no tiene columnas RutBeneficiario y RutTitular; exporto IDs sin enriquecimiento.\")\n",
        "else:\n",
        "    print(f\"Aviso: no encuentro {CLI_PATH}; exporto IDs sin enriquecimiento.\")\n",
        "\n",
        "# Export\n",
        "ids_out = ROOT / \"data\" / \"processed\" / \"activos_ids_v2_plus.csv\"\n",
        "ids_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "ids_v2.to_csv(ids_out, index=False, encoding=\"utf-8\")\n",
        "print(\"IDs v2 PLUS exportados a:\", ids_out.resolve())\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a19e045",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
